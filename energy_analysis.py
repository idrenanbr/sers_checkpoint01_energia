"""
energy_analysis.py
-------------------

This script performs a series of exploratory analyses on the UCI Individual Household
Electric Power Consumption dataset. It replicates the steps from a typical data
science assignment and saves intermediate results to CSV files and figures to
PNG files in a reproducible way. The script can be run standalone from the
command line and assumes the raw text file is available in the same directory
or passed as an argument.

Usage:
    python energy_analysis.py --data household_power_consumption.txt --out outputs

The script will create the output directory if it does not exist and write
several CSVs and figures summarising the analysis.

Author: Generated by ChatGPT
"""

import argparse
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.linear_model import LinearRegression

# Statsmodels is only used for time series decomposition. It is optional
try:
    from statsmodels.tsa.seasonal import seasonal_decompose
    _HAS_STATSMODELS = True
except ImportError:
    _HAS_STATSMODELS = False


def load_data(path: str) -> pd.DataFrame:
    """Load the dataset from a semicolon-separated text file.

    Missing values are denoted by '?' in the raw file. We convert them to NaN
    and coerce numeric columns to floats. The Date and Time columns are
    combined into a single datetime index for easier time-series analysis.

    Parameters
    ----------
    path : str
        Path to the raw data file.

    Returns
    -------
    pd.DataFrame
        Preprocessed dataframe with a datetime index and numeric columns.
    """
    # Define column types: treat all numeric columns as floats
    cols = [
        "Date",
        "Time",
        "Global_active_power",
        "Global_reactive_power",
        "Voltage",
        "Global_intensity",
        "Sub_metering_1",
        "Sub_metering_2",
        "Sub_metering_3",
    ]
    df = pd.read_csv(
        path,
        sep=";",
        names=cols,
        header=0,
        na_values="?",
        low_memory=False,
    )
    # Combine Date and Time into a datetime column
    df["Datetime"] = pd.to_datetime(df["Date"] + " " + df["Time"], format="%d/%m/%Y %H:%M:%S")
    df = df.drop(columns=["Date", "Time"])
    # Convert numeric columns to floats
    num_cols = [
        "Global_active_power",
        "Global_reactive_power",
        "Voltage",
        "Global_intensity",
        "Sub_metering_1",
        "Sub_metering_2",
        "Sub_metering_3",
    ]
    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors="coerce")
    df = df.set_index("Datetime")
    return df


def prepare(df: pd.DataFrame) -> pd.DataFrame:
    """Add additional helper columns to the dataframe.

    Creates a weekday name column and a Total_Sub_metering column.
    """
    df = df.copy()
    df["weekday"] = df.index.day_name()
    df["Total_Sub_metering"] = df[["Sub_metering_1", "Sub_metering_2", "Sub_metering_3"]].sum(axis=1)
    return df


def ensure_dir(path: str):
    if not os.path.exists(path):
        os.makedirs(path)


def save_csv(df: pd.DataFrame, path: str, name: str):
    """Save a dataframe to CSV in the output directory."""
    ensure_dir(path)
    df.to_csv(os.path.join(path, f"{name}.csv"), index=True)


def save_fig(fig, path: str, name: str):
    """Save a matplotlib figure to the output directory and close it."""
    ensure_dir(path)
    fig.savefig(os.path.join(path, f"{name}.png"), bbox_inches="tight")
    plt.close(fig)


def compute_and_save(df: pd.DataFrame, out_dir: str):
    """Perform the analyses and save results to the output directory."""
    # 1. First ten rows
    head10 = df.head(10)
    save_csv(head10, out_dir, "head10")

    # 3. Missing values count
    missing_counts = df.isna().sum()
    missing_counts.to_csv(os.path.join(out_dir, "missing_counts.csv"), header=["missing"])

    # 5. Mean daily consumption for 2007 (Global_active_power)
    df_2007 = df.loc[(df.index.year == 2007)]
    daily_mean_2007 = df_2007["Global_active_power"].resample("D").mean()
    daily_mean_2007_value = daily_mean_2007.mean()
    # Save the daily means and summary
    daily_mean_2007.to_csv(os.path.join(out_dir, "daily_mean_2007.csv"), header=["daily_mean_ga"], index_label="date")
    pd.DataFrame({"value": [daily_mean_2007_value]}).to_csv(os.path.join(out_dir, "daily_mean_2007_value.csv"), index=False)

    # 6. Line plot for a single day (choose an arbitrary day with complete data)
    # We'll use 2008-03-15 as a representative day.
    day_selection = df.loc["2008-03-15"]
    fig, ax = plt.subplots()
    day_selection["Global_active_power"].plot(ax=ax)
    ax.set_title("Global Active Power on 2008-03-15")
    ax.set_xlabel("Time")
    ax.set_ylabel("Global Active Power (kilowatts)")
    save_fig(fig, out_dir, "global_active_power_day")

    # 7. Voltage histogram
    fig, ax = plt.subplots()
    df["Voltage"].plot(kind="hist", bins=100, ax=ax)
    ax.set_title("Histogram of Voltage")
    ax.set_xlabel("Voltage")
    ax.set_ylabel("Frequency")
    save_fig(fig, out_dir, "voltage_hist")
    # Voltage descriptive stats
    voltage_stats = df["Voltage"].describe()
    voltage_stats.to_csv(os.path.join(out_dir, "voltage_stats.csv"), header=["stat"])

    # 8. Mean monthly consumption across entire period
    monthly_mean = df["Global_active_power"].resample("M").mean()
    monthly_mean.to_csv(os.path.join(out_dir, "monthly_mean.csv"), header=["mean_global_active_power"], index_label="month")

    # 9. Day with maximum total global active power
    daily_sum = df["Global_active_power"].resample("D").sum()
    max_day = daily_sum.idxmax()
    max_day_value = daily_sum.max()
    pd.DataFrame({"max_day": [max_day], "max_total_global_active_power": [max_day_value]}).to_csv(
        os.path.join(out_dir, "max_day.csv"), index=False
    )

    # 10. Weekday vs weekend mean comparison
    df["is_weekend"] = df.index.weekday >= 5
    weekday_mean = df.loc[~df["is_weekend"], "Global_active_power"].mean()
    weekend_mean = df.loc[df["is_weekend"], "Global_active_power"].mean()
    pd.DataFrame({"type": ["weekday", "weekend"], "mean_global_active_power": [weekday_mean, weekend_mean]}).to_csv(
        os.path.join(out_dir, "weekday_vs_weekend.csv"), index=False
    )

    # 11. Correlation matrix among selected variables
    corr_matrix = df[[
        "Global_active_power",
        "Global_reactive_power",
        "Voltage",
        "Global_intensity",
    ]].corr()
    corr_matrix.to_csv(os.path.join(out_dir, "correlation_matrix.csv"))

    # 13. Months where Total_Sub_metering mean exceeds Global_active_power mean
    monthly_tot_sub = df["Total_Sub_metering"].resample("M").mean()
    monthly_ga = df["Global_active_power"].resample("M").mean()
    exceed_months = monthly_tot_sub[monthly_tot_sub > monthly_ga]
    exceed_months.to_csv(os.path.join(out_dir, "months_exceed.csv"), header=["mean_total_sub_metering"], index_label="month")

    # 14. Voltage time series for 2008
    voltage_2008 = df.loc[str(2008), "Voltage"]
    fig, ax = plt.subplots()
    voltage_2008.plot(ax=ax)
    ax.set_title("Voltage in 2008")
    ax.set_xlabel("Date")
    ax.set_ylabel("Voltage")
    save_fig(fig, out_dir, "voltage_2008")

    # 15. Compare summer vs winter (north hemisphere). Summer: June-August, Winter: Dec-Feb
    summer = df[df.index.month.isin([6, 7, 8])]["Global_active_power"].mean()
    winter = df[df.index.month.isin([12, 1, 2])]["Global_active_power"].mean()
    pd.DataFrame({"season": ["summer", "winter"], "mean_global_active_power": [summer, winter]}).to_csv(
        os.path.join(out_dir, "season_comparison.csv"), index=False
    )

    # 16. Sampling 1% and comparing distribution of Global_active_power
    sample_df = df.sample(frac=0.01, random_state=42)
    # Save distribution statistics of both full and sample
    full_desc = df["Global_active_power"].describe()
    sample_desc = sample_df["Global_active_power"].describe()
    full_desc.to_csv(os.path.join(out_dir, "full_distribution_global_active_power.csv"), header=["stat_full"])
    sample_desc.to_csv(os.path.join(out_dir, "sample_distribution_global_active_power.csv"), header=["stat_sample"])
    # Plot histogram comparison
    fig, ax = plt.subplots()
    df["Global_active_power"].plot(kind="hist", bins=100, density=True, alpha=0.5, label="Full", ax=ax)
    sample_df["Global_active_power"].plot(kind="hist", bins=100, density=True, alpha=0.5, label="Sample 1%", ax=ax)
    ax.legend()
    ax.set_title("Distribution of Global Active Power: Full vs 1% Sample")
    ax.set_xlabel("Global Active Power (kilowatts)")
    ax.set_ylabel("Density")
    save_fig(fig, out_dir, "global_active_power_distribution_comparison")

    # 17. Min-Max scaling for numeric variables
    scaler = MinMaxScaler()
    numeric_cols = [
        "Global_active_power",
        "Global_reactive_power",
        "Voltage",
        "Global_intensity",
        "Sub_metering_1",
        "Sub_metering_2",
        "Sub_metering_3",
        "Total_Sub_metering",
    ]
    scaled_array = scaler.fit_transform(df[numeric_cols].fillna(0))
    scaled_df = pd.DataFrame(scaled_array, columns=numeric_cols, index=df.index)
    # Save summary statistics of scaled data (min and max should be 0 and 1)
    scaled_summary = scaled_df.describe().loc[["min", "max", "mean", "std"]]
    scaled_summary.to_csv(os.path.join(out_dir, "scaled_minmax_summary.csv"))

    # 18. K-Means clustering on daily aggregated consumption (3 clusters)
    daily_features = pd.DataFrame({
        "mean_ga": df["Global_active_power"].resample("D").mean(),
        "mean_gr": df["Global_reactive_power"].resample("D").mean(),
        "mean_intensity": df["Global_intensity"].resample("D").mean(),
        "sum_sub": df["Total_Sub_metering"].resample("D").sum(),
    }).dropna()
    # Fill NaNs just in case
    X = daily_features.values
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X)
    daily_features["cluster"] = labels
    centers = pd.DataFrame(kmeans.cluster_centers_, columns=daily_features.columns[:-1])
    # Save cluster counts and centers
    cluster_counts = daily_features["cluster"].value_counts().sort_index()
    pd.DataFrame({"cluster": cluster_counts.index, "count": cluster_counts.values}).to_csv(
        os.path.join(out_dir, "kmeans_cluster_counts.csv"), index=False
    )
    centers.to_csv(os.path.join(out_dir, "kmeans_cluster_centers.csv"), index_label="cluster")

    # 19. Time series decomposition (first 6 months of 2007)
    if _HAS_STATSMODELS:
        half_year = df.loc["2007-01-01":"2007-06-30", "Global_active_power"].resample("D").mean().dropna()
        decomposition = seasonal_decompose(half_year, model="additive", period=7)  # weekly seasonality
        fig = decomposition.plot()
        fig.suptitle("Seasonal Decomposition of Global Active Power (Jan-Jun 2007)")
        save_fig(fig, out_dir, "decomposition_global_active_power")
    else:
        print("statsmodels not available; skipping decomposition")

    # 20. Linear regression: predict Global_active_power from Global_intensity
    # Use rows where both columns are non-null
    valid_rows = df[["Global_active_power", "Global_intensity"]].dropna()
    X = valid_rows[["Global_intensity"]]
    y = valid_rows["Global_active_power"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    preds = lr.predict(X_test)
    rmse = mean_squared_error(y_test, preds, squared=False)
    mae = mean_absolute_error(y_test, preds)
    r2 = lr.score(X_test, y_test)
    pd.DataFrame({
        "coefficient": [float(lr.coef_[0])],
        "intercept": [float(lr.intercept_)],
        "rmse": [rmse],
        "mae": [mae],
        "r2": [r2],
    }).to_csv(os.path.join(out_dir, "linear_regression_metrics.csv"), index=False)

    # Save also cluster assignments for reference
    daily_features.to_csv(os.path.join(out_dir, "daily_features_with_cluster.csv"))


def main():
    parser = argparse.ArgumentParser(description="Perform analyses on electric power consumption data.")
    parser.add_argument("--data", required=True, help="Path to household_power_consumption.txt")
    parser.add_argument("--out", default="outputs", help="Directory to write output files")
    args = parser.parse_args()

    df_raw = load_data(args.data)
    df = prepare(df_raw)
    compute_and_save(df, args.out)


if __name__ == "__main__":
    main()